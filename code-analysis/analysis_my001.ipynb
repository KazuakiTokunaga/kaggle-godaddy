{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fae5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbab0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my modules.\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "current_dir = os.path.join(Path().resolve())\n",
    "sys.path.append(str(current_dir) + '/../')\n",
    "\n",
    "from modules import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d906464",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc24d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "USE_LAG = 5\n",
    "USE_OLD_LOG = False\n",
    "USE_TREND=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b83519",
   "metadata": {},
   "source": [
    "## Import data and create basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708b576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '../input/'\n",
    "date_col = 'first_day_of_month'\n",
    "cat_cols = ['county', 'state']\n",
    "mbd = 'microbusiness_density'\n",
    "idx = 'row_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d15067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = pd.read_csv(BASE + 'census_starter.csv', index_col='cfips')\n",
    "df_train = pd.read_csv(BASE + 'train.csv',  index_col=idx)\n",
    "df_test = pd.read_csv(BASE + 'test.csv',  index_col=idx)\n",
    "df_subm = pd.read_csv(BASE + 'sample_submission.csv',  index_col=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649a914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = df_train[['cfips', 'state', 'county']]\n",
    "state_dict = state_dict.set_index('cfips')\n",
    "state_dict = state_dict.drop_duplicates()\n",
    "state_dict = state_dict.to_dict()\n",
    "\n",
    "df_test['state'] = df_test['cfips'].map(state_dict['state'])\n",
    "df_test['county'] = df_test['cfips'].map(state_dict['county'])\n",
    "\n",
    "df_all = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "df_all[date_col] = pd.to_datetime(df_all[date_col])\n",
    "\n",
    "df_all['year'] = df_all[date_col].dt.year\n",
    "df_all['month'] = df_all[date_col].dt.month\n",
    "df_all['scale'] = (df_all[date_col] - df_all[date_col].min()).dt.days\n",
    "df_all['scale'] = df_all['scale'].factorize()[0]\n",
    "\n",
    "df_all = df_all.drop(columns=[date_col])\n",
    "df_all.sort_index(inplace=True)\n",
    "\n",
    "df_all[cat_cols] = df_all[cat_cols].astype('category')\n",
    "\n",
    "# df_all.to_csv('../output/df_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef8474",
   "metadata": {},
   "source": [
    "## Join features created by other codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d559a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feature_season = pd.read_csv('../output/feature_season.csv')\n",
    "\n",
    "# df_all.reset_index(inplace=True)\n",
    "# df_all = df_all.merge(df_feature_season, how='left', on='row_id')\n",
    "# df_all.set_index('row_id', inplace=True)\n",
    "\n",
    "# df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a2dcd",
   "metadata": {},
   "source": [
    "## Create features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1140aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30, 39):\n",
    "    dt = df_all.loc[df_all.scale==i].groupby('cfips')['active'].agg('last')\n",
    "    df_all[f'select_lastactive{i}'] = df_all['cfips'].map(dt)\n",
    "\n",
    "    dt = df_all.loc[df_all.scale==i].groupby('cfips')['microbusiness_density'].agg('last')\n",
    "    df_all[f'select_lastmbd{i}'] = df_all['cfips'].map(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1fa9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    df_all[f'select_rate{i}'] = df_all.groupby('cfips')[mbd].shift(i).bfill()\n",
    "    df_all[f'select_rate{i}'] = (df_all[mbd] / df_all[f'select_rate{i}'] - 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf35ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    for j in range(i, i + USE_LAG):\n",
    "        df_all[f'select_rate{i}_lag{j}'] = df_all[f'select_rate{i}'].shift(j) \n",
    "\n",
    "# df_all.to_csv('../output/df_all_lag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "869520c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.set_index('cfips')\n",
    "\n",
    "df_all[df_census.columns] = df_census\n",
    "\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.set_index('row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1bb5e",
   "metadata": {},
   "source": [
    "## Run Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "544906a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features = ['cfips', 'county', 'state', 'microbusiness_density', 'active', 'year','month', 'scale', \n",
    "                                 'mbd_pred', 'y_base', 'y_pred', 'y_target', 'smape']\n",
    "\n",
    "def regularize(x):\n",
    "    if x >= 1:\n",
    "        if x * 0.999 >= 1:\n",
    "            x *= 0.999\n",
    "        else:\n",
    "            x = 1\n",
    "    else:\n",
    "        if x * 1.001 <= 1:\n",
    "            x *= 1.001\n",
    "        else:\n",
    "            x = 1\n",
    "    return x\n",
    "\n",
    "def get_trend_dict(valid_time, pred_m = 1, n=3, thre=2, active_thre=25000):\n",
    "    target=mbd\n",
    "    df_target_lag = df_all.loc[(df_all['scale'] >= valid_time - pred_m - n)&(df_all['scale']<=valid_time-pred_m), ['cfips','scale','active',target]].copy()\n",
    "    # df_target_lag[target] += 1 # これは本来は不要だった\n",
    "    for i in range(1, n+1):\n",
    "        df_target_lag[f'lag_{i}'] = df_target_lag[target].shift(i)\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        if i==1:\n",
    "            df_target_lag[f'rate{i}'] = df_target_lag[target] / df_target_lag[f'lag_{i}']\n",
    "        else:\n",
    "            df_target_lag[f'rate{i}'] = df_target_lag[f'lag_{i-1}'] / df_target_lag[f'lag_{i}']        \n",
    "\n",
    "    df_target_lag['up_cnt'] = 0\n",
    "    df_target_lag['down_cnt'] = 0\n",
    "    df_target_lag['mean'] = 0\n",
    "    for i in range(1, n+1):\n",
    "        df_target_lag['up_cnt'] += (df_target_lag[f'rate{i}'] > 1)*1\n",
    "        df_target_lag['down_cnt'] += (df_target_lag[f'rate{i}']<1)*1\n",
    "        df_target_lag['mean'] += df_target_lag[f'rate{i}']\n",
    "    df_target_lag['mean'] /= n\n",
    "\n",
    "    df_target_lag['trend'] = df_target_lag[['up_cnt', 'mean']].apply(lambda x: x[1] if x[0] >= thre and x[1]>1 else np.nan, axis=1)\n",
    "    df_target_lag['trend'] = df_target_lag[['down_cnt', 'mean', 'trend']].apply(lambda x: x[1] if x[0] >= thre and x[1]<1 else x[2], axis=1)\n",
    "    idx = (df_target_lag['scale']==valid_time-pred_m)&(df_target_lag['active']>=active_thre)&(~df_target_lag['trend'].isna())\n",
    "    df_trend = df_target_lag[idx].copy()\n",
    "    #df_trend['trend'] = df_trend['trend'].apply(regularize)\n",
    "    df_trend['trend'] = df_trend['trend'].clip(0.995, 1.005)\n",
    "    trend_dict = df_trend[['cfips', 'trend']].set_index('cfips').to_dict()['trend']\n",
    "    \n",
    "    return trend_dict\n",
    "\n",
    "\n",
    "def run_fit_predict(valid_time, pred_m):\n",
    "\n",
    "    train_times = valid_time - pred_m\n",
    "    \n",
    "    print('valid_times: ', valid_time)\n",
    "    print('pred_m: ', pred_m)\n",
    "    print('train_times: ', train_times)\n",
    "\n",
    "    drop_features = ['microbusiness_density', 'active', 'scale']\n",
    "    features = list(filter(lambda x: (not x.startswith('select_') and (x not in drop_features)),  df_all.columns.to_list()))\n",
    "    \n",
    "    # Select appropriate lastactive and lastmbd features.\n",
    "    features.append(f'select_lastactive{train_times}')\n",
    "    features.append(f'select_lastmbd{train_times}')\n",
    "    \n",
    "    # Select appropriate target and lag features.\n",
    "    target = f'select_rate{pred_m}'\n",
    "    for i in range(pred_m, pred_m + USE_LAG):\n",
    "        features.append(f'select_rate{pred_m}_lag{i}')\n",
    "\n",
    "    # Extract Valid and Train data.\n",
    "    if USE_OLD_LOG:\n",
    "        train_indices = (df_all['scale']<=train_times) & (df_all['scale']>=pred_m)\n",
    "    else:\n",
    "        train_indices = (df_all['scale']<=train_times) & (df_all['scale']>=pred_m + USE_LAG)\n",
    "\n",
    "    X_train = df_all.loc[train_indices, features]\n",
    "    y_train = df_all.loc[train_indices, target]\n",
    "\n",
    "    valid_indices = (df_all['scale']==valid_time)\n",
    "    X_valid = df_all.loc[valid_indices, features]\n",
    "    y_valid = df_all.loc[valid_indices, target]\n",
    "    \n",
    "    # Create Model and predict.\n",
    "    params = {\n",
    "        'n_iter': 200,\n",
    "        'verbosity': -1,\n",
    "        'objective': 'l1',\n",
    "        'random_state': 42,\n",
    "        'extra_trees': True,\n",
    "        'colsample_bytree': 0.8841279649367693,\n",
    "        'colsample_bynode': 0.10142964450634374,\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.013647749926797374,\n",
    "        'lambda_l1': 1.8386216853616875,\n",
    "        'lambda_l2': 7.557660410418351,\n",
    "        'num_leaves': 61,\n",
    "        'min_data_in_leaf': 213\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Convert y_pred to microbusiness_density prediction and create output dataset.\n",
    "    df_valid = df_all.loc[valid_indices].copy()\n",
    "    df_valid['y_pred'] = y_pred\n",
    "    df_valid['y_target'] = y_valid\n",
    "    base_indices = (df_all['scale']==valid_time-pred_m)\n",
    "    base_y = df_all.loc[base_indices, ['cfips', 'microbusiness_density']]\n",
    "    base_dict = base_y.set_index('cfips').to_dict()\n",
    "    df_valid['y_base'] = df_valid['cfips'].map(base_dict['microbusiness_density'])\n",
    "    df_valid['mbd_pred'] = df_valid['y_base'] * (df_valid['y_pred']+1)\n",
    "    \n",
    "    if USE_TREND and pred_m == 1:\n",
    "        trend_dict = get_trend_dict(valid_time, pred_m, 3, 3, 5000)\n",
    "        print('# of cfips that have trend :', len(trend_dict))\n",
    "        for cfip in trend_dict:\n",
    "            df_valid.loc[df_valid['cfips']==cfip, 'mbd_pred'] = df_valid.loc[df_valid['cfips']==cfip, 'y_base'] * trend_dict[cfip]\n",
    "    \n",
    "    df_valid['smape'] = utils.smape_arr(df_valid['microbusiness_density'], df_valid['mbd_pred'])\n",
    "    df_output = df_valid[output_features]\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "\n",
    "def run_validation_for_pred_m(validation_times, pred_ms):\n",
    "    \n",
    "    df_output = pd.DataFrame(columns=output_features)\n",
    "    for validation_time, pred_m in zip(validation_times, pred_ms):\n",
    "        df = run_fit_predict(validation_time, pred_m)\n",
    "        df_output = pd.concat([df, df_output])\n",
    "\n",
    "    return df_output.reset_index().rename(columns={'index': 'row_id'}).set_index('row_id')\n",
    "\n",
    "\n",
    "def run_validation(max_month=38, m_len=5, pred_ms = [1,2,3,4]):\n",
    "    \n",
    "        validation_times = [max_month - i for i in range(m_len)]\n",
    "        \n",
    "        output_dic = dict()\n",
    "        for pred_m in pred_ms:\n",
    "            pred_m_len = [pred_m] * m_len\n",
    "            df_output = run_validation_for_pred_m(validation_times, pred_m_len)\n",
    "            output_dic[pred_m] = df_output\n",
    "        \n",
    "        return output_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f1e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_scores_summary(output_dic, pred_ms = [1,2,3,4], filename='validation_score'):\n",
    "    output_array = np.zeros((4, 2))\n",
    "    for pred_m in pred_ms:\n",
    "        df = output_dic[pred_m]\n",
    "        output_array[pred_m-1] = df.groupby('scale')['smape'].mean().describe()[['mean', 'std']].to_numpy()\n",
    "\n",
    "    df = pd.DataFrame(output_array, columns=['mean', 'std'], index=[1,2,3,4])\n",
    "    df.to_csv(f'../output/{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74c5cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_times:  38\n",
      "pred_m:  1\n",
      "train_times:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 91\n",
      "valid_times:  37\n",
      "pred_m:  1\n",
      "train_times:  36\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 91\n",
      "valid_times:  36\n",
      "pred_m:  1\n",
      "train_times:  35\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 17\n",
      "valid_times:  35\n",
      "pred_m:  1\n",
      "train_times:  34\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 33\n",
      "valid_times:  34\n",
      "pred_m:  1\n",
      "train_times:  33\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 21\n",
      "valid_times:  38\n",
      "pred_m:  2\n",
      "train_times:  36\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  37\n",
      "pred_m:  2\n",
      "train_times:  35\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  36\n",
      "pred_m:  2\n",
      "train_times:  34\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  35\n",
      "pred_m:  2\n",
      "train_times:  33\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  34\n",
      "pred_m:  2\n",
      "train_times:  32\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  38\n",
      "pred_m:  3\n",
      "train_times:  35\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  37\n",
      "pred_m:  3\n",
      "train_times:  34\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  36\n",
      "pred_m:  3\n",
      "train_times:  33\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  35\n",
      "pred_m:  3\n",
      "train_times:  32\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  34\n",
      "pred_m:  3\n",
      "train_times:  31\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_times:  38\n",
      "pred_m:  4\n",
      "train_times:  34\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  37\n",
      "pred_m:  4\n",
      "train_times:  33\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  36\n",
      "pred_m:  4\n",
      "train_times:  32\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  35\n",
      "pred_m:  4\n",
      "train_times:  31\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  34\n",
      "pred_m:  4\n",
      "train_times:  30\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n"
     ]
    }
   ],
   "source": [
    "output_dic = run_validation(38, 5)\n",
    "export_scores_summary(output_dic, pred_ms = [1], filename=f'lgbm_baseline_{USE_LAG}_{USE_OLD_LOG}_{USE_TREND}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68996886",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(output_dic, 'result_lgbm_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414d803",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481a3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(filename=''):\n",
    "    df_pred = run_validation_for_pred_m([39,40,41,42], [1,2,3,4])\n",
    "    \n",
    "    df_merged = pd.merge(df_subm, df_pred['mbd_pred'], how='left', on='row_id')\n",
    "    df_merged.loc[~df_merged['mbd_pred'].isna(), 'microbusiness_density'] = df_merged['mbd_pred']\n",
    "    df_submission = df_merged['microbusiness_density']\n",
    "    \n",
    "    if filename:\n",
    "        df_submission.to_csv(f'../submission/{filename}.csv')\n",
    "        print(f'saved {filename}')\n",
    "        \n",
    "    return df_pred, df_merged, df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3060e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_times:  39\n",
      "pred_m:  1\n",
      "train_times:  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "# of cfips that have trend : 11\n",
      "valid_times:  40\n",
      "pred_m:  2\n",
      "train_times:  38\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  41\n",
      "pred_m:  3\n",
      "train_times:  38\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "valid_times:  42\n",
      "pred_m:  4\n",
      "train_times:  38\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8386216853616875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8386216853616875\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.557660410418351, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.557660410418351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=213, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=213\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "saved lgbm_baseline_trend\n"
     ]
    }
   ],
   "source": [
    "df_pred, df_merged, submission = create_submission(filename='lgbm_baseline_trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0f9b9",
   "metadata": {},
   "source": [
    "### Ensemble with Best Score Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5042d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_base = pd.read_csv('../submission/submission_10842.csv',  index_col='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ca4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m=1\n",
    "valid_time=39\n",
    "trend_dict = get_trend_dict(valid_time, pred_m, 3, 3, 25000)\n",
    "    \n",
    "utils.save_pickle(trend_dict, 'trend_dict_3_3_25000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99519c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfip in trend_dict:\n",
    "    row_id = str(cfip) + '_2022-11-01'\n",
    "    \n",
    "    #　replace\n",
    "    #　df_sub_base.loc[row_id, :] = (trend_dict[cfip] * df_all.loc[(df_all['scale']==38)&(df_all['cfips']==cfip), mbd]).values[0]\n",
    "    \n",
    "    trend_values = (trend_dict[cfip] * df_all.loc[(df_all['scale']==38)&(df_all['cfips']==cfip), mbd]).values[0]\n",
    "    df_sub_base.loc[row_id, :] = (df_sub_base.loc[row_id].values[0] + trend_values) / 2\n",
    "    \n",
    "df_sub_base.to_csv('../submission/submission_10842_trend_ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43783c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
